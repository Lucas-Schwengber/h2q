{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/dyna_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.lines as mlines\n",
    "from src.utils.losses import L2\n",
    "import torch\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "\n",
    "benchmarks = [\"DPSH\", \"HashNet\", \"CEL\", \"DCH\", \"DHN\", \"WGLHH\", \n",
    "              \"HyP2\"\n",
    "             ]\n",
    "dbs = [\"CIFAR_10\", \"NUS_WIDE\", \"MS_COCO\", \"ImageNet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect results from main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features(features, val=\"col\"):\n",
    "    if val==\"col\":\n",
    "            val = np.sqrt(features.shape[-1])\n",
    "    return features / np.linalg.norm(features, axis=1)[:, np.newaxis] * val\n",
    "\n",
    "def get_quantization_error(dir, datafolds=[\"val\", \"query\"]):\n",
    "\n",
    "    model_dir = pathlib.Path(str(dir).replace(\"eval\",\"models\"))\n",
    "    l2_errors = {}\n",
    "\n",
    "    for datafold in datafolds:\n",
    "        features_path = model_dir / f\"{datafold}-features.npy\" \n",
    "        features = norm_features(np.load(features_path), val = \"col\")\n",
    "        l2_errors[datafold] = L2()(torch.tensor(features), None).item()\n",
    "\n",
    "    return l2_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "results = []\n",
    "for db in dbs:\n",
    "    BENCH_EVAL_DIR = pathlib.Path(f\"/impa/home/a/lucas.resende/dyna_hash/eval/QS/{db}/rotation_experiment\")\n",
    "    ROT_EVAL_DIR = pathlib.Path(f\"/impa/home/a/lucas.resende/dyna_hash/eval/HHNN/{db}/rotation_experiment\")\n",
    "    ITQ_EVAL_DIR = pathlib.Path(f\"/impa/home/a/lucas.resende/dyna_hash/eval/ITQ/{db}/rotation_experiment\")\n",
    "    ADSH_EVAL_DIR = pathlib.Path(f\"/impa/home/a/lucas.resende/dyna_hash/eval/ADSH/{db}/rotation_experiment\")\n",
    "\n",
    "    for d in tqdm(ADSH_EVAL_DIR.glob(\"*\")):\n",
    "        if ( d / f\"val-prediction_mAP.json\" ).exists():\n",
    "            nbits = int(d.name.split(\"-nbits=\")[-1].split(\"-\")[0])\n",
    "            seed = int(d.name.split(\"-seed=\")[-1].split(\"-\")[0])\n",
    "            arch = d.name.split(\"-arch=\")[-1].split(\"-\")[0]\n",
    "            results.append(\n",
    "                {\"db\": db, \"loss\": \"ADSH\", \"nbits\": nbits,\n",
    "                 \"r_loss\": '-', \"seed\": seed, \"arch\": arch, \"penalty\": '-',\n",
    "                 \"L2_penalty\": '-', \"HSWD_penalty\": '-', \"no_cube\": '-'\n",
    "                }\n",
    "            )\n",
    "            for fold in [\"val\", \"query\"]:\n",
    "                exp_results = json.load(open( d / f\"{fold}-prediction_mAP.json\", \"r\" ))\n",
    "                for metric in [\"mAP_at_k=1000\", \"mAP_at_k=5000\"]:\n",
    "                    results[-1][f\"{fold}_{metric}\"] = exp_results[metric]*100\n",
    "\n",
    "    for EVAL_DIR in [BENCH_EVAL_DIR, ROT_EVAL_DIR, ITQ_EVAL_DIR]:\n",
    "        for d in tqdm(EVAL_DIR.glob(\"*\")):\n",
    "            loss = d.name.split(\"-loss=\")[-1].split(\"-\")[0]\n",
    "            penalty = d.name.split(\"-penalty=\")[-1].split(\"-\")[0]\n",
    "            pass_HyP2 = True\n",
    "            if loss == \"HyP2\":\n",
    "                pass_HyP2 = (penalty == \"1.25\" and db != \"NUS_WIDE\") or (penalty == \"0.75\" and db == \"NUS_WIDE\")\n",
    "            if ( d / f\"val-prediction_mAP.json\" ).exists() and loss in benchmarks and pass_HyP2:\n",
    "                nbits = int(d.name.split(\"-nbits=\")[-1].split(\"-\")[0])\n",
    "                seed = int(d.name.split(\"-seed=\")[-1].split(\"-\")[0])\n",
    "                arch = d.name.split(\"-arch=\")[-1].split(\"-\")[0]\n",
    "                L2_penalty = \"L2_penalty\" in d.name\n",
    "                HSWD_penalty = \"HSWD_penalty\" in d.name\n",
    "                L2_penalty = L2_penalty and not HSWD_penalty\n",
    "                no_cube = \"no_cube\" in d.name\n",
    "\n",
    "                r_loss = \"-\"\n",
    "                if \"r_loss\" in d.name:\n",
    "                    r_loss = d.name.split(\"-r_loss=\")[-1].split(\"-\")[0]\n",
    "                if EVAL_DIR == ITQ_EVAL_DIR:\n",
    "                    r_loss = \"ITQ\"\n",
    "\n",
    "                l2_errors = get_quantization_error(d)\n",
    "\n",
    "                results.append(\n",
    "                    {\"db\": db, \"loss\": loss, \"nbits\": nbits,\n",
    "                     \"r_loss\": r_loss, \"seed\": seed, \"arch\": arch, \"penalty\": penalty,\n",
    "                     \"L2_penalty\": L2_penalty, \"HSWD_penalty\": HSWD_penalty, \"no_cube\": no_cube,\n",
    "                     \"val_l2_qe\":l2_errors[\"val\"] ,\"query_l2_qe\": l2_errors[\"query\"]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                for fold in [\"val\", \"query\"]:\n",
    "                    exp_results = json.load(open( d / f\"{fold}-prediction_mAP.json\", \"r\" ))\n",
    "                    for metric in [\"mAP_at_k=1000\", \"mAP_at_k=5000\"]:\n",
    "                        results[-1][f\"{fold}_{metric}\"] = exp_results[metric]*100\n",
    "\n",
    "raw_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mAP at k using k=1000 to imagenet and k=5000 to other databases\n",
    "raw_results[\"val_mAP\"] = raw_results[\"val_mAP_at_k=1000\"]*(raw_results.db == \"ImageNet\") + raw_results[\"val_mAP_at_k=5000\"]*(raw_results.db != \"ImageNet\")\n",
    "raw_results[\"query_mAP\"] = raw_results[\"query_mAP_at_k=1000\"]*(raw_results.db == \"ImageNet\") + raw_results[\"query_mAP_at_k=5000\"]*(raw_results.db != \"ImageNet\")\n",
    "del raw_results[\"val_mAP_at_k=1000\"]\n",
    "del raw_results[\"val_mAP_at_k=5000\"]\n",
    "del raw_results[\"query_mAP_at_k=1000\"]\n",
    "del raw_results[\"query_mAP_at_k=5000\"]\n",
    "\n",
    "#average over seeds with all other parameters fixed\n",
    "fixed_cols = [\"db\",\"loss\",\"nbits\",\"r_loss\",\"arch\",\"penalty\",\"L2_penalty\",\"HSWD_penalty\",\"no_cube\"]\n",
    "raw_results = raw_results.groupby(fixed_cols).agg({\"val_l2_qe\":['mean','std'],\"query_l2_qe\":['mean','std'],'val_mAP':['mean','std'], 'query_mAP':['mean','std']}).reset_index()\n",
    "raw_results.columns = fixed_cols + [\"val_l2_qe\", \"val_l2_qe_std\", \"query_l2_qe\", \"query_l2_qe_std\", \"val_mAP\", \"val_mAP_std\", \"query_mAP\", \"query_mAP_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the right experimental configuration from the parameters\n",
    "def get_configuration(row):\n",
    "    if row[\"loss\"] == \"ADSH\":\n",
    "        return \"ADSH\"\n",
    "    elif row[\"loss\"] == \"HashNet\":\n",
    "        if row[\"r_loss\"] == \"-\":\n",
    "            return \"continuation\"\n",
    "        else:\n",
    "            return \"-\"\n",
    "    elif row[\"HSWD_penalty\"]:\n",
    "        return \"HSWD\"\n",
    "    elif row[\"r_loss\"] == \"ITQ\":\n",
    "        return \"l0+ITQ\"\n",
    "    elif row[\"r_loss\"] in [\"L2\", \"L1\", \"bit_var_loss\", \"min_entry\"]:\n",
    "        return \"l0+H2Q+\"+row[\"r_loss\"]\n",
    "    else:\n",
    "        has_penalty = row[\"L2_penalty\"] or ( row[\"loss\"] not in [\"HyP2\", \"CEL\"] and row[\"penalty\"] != \"0.0\" )\n",
    "        if has_penalty:\n",
    "            return \"l>0\"\n",
    "        else:\n",
    "            return \"l0\"\n",
    "raw_results[\"strategy\"] = raw_results.apply(lambda row: get_configuration(row), axis=1)\n",
    "\n",
    "# delete the parameters that are now incorporated in the configuration\n",
    "del raw_results[\"no_cube\"]\n",
    "del raw_results[\"r_loss\"]\n",
    "del raw_results[\"L2_penalty\"]\n",
    "del raw_results[\"HSWD_penalty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best penalizations on the l>0 strategy\n",
    "lg0 = raw_results[raw_results.strategy == \"l>0\"]\n",
    "lg0 = lg0.loc[lg0.groupby([\"db\", \"loss\", \"nbits\", \"arch\", \"strategy\"])['val_mAP'].idxmax()][[\"db\", \"loss\", \"nbits\", \"arch\",\"query_l2_qe\", \"query_l2_qe_std\", \"query_mAP\", \"query_mAP_std\", \"strategy\"]]\n",
    "\n",
    "# join with the rest of the data\n",
    "non_lg0 = raw_results[raw_results.strategy != \"l>0\"]\n",
    "del non_lg0[\"penalty\"]\n",
    "del non_lg0[\"val_mAP\"]\n",
    "del non_lg0[\"val_mAP_std\"]\n",
    "del non_lg0[\"val_l2_qe\"]\n",
    "del non_lg0[\"val_l2_qe_std\"]\n",
    "\n",
    "# use DHN to fill DPSH on the non_l>0 case\n",
    "# since they have the same similarity loss\n",
    "non_lg0 = non_lg0[ non_lg0.loss != \"DPSH\" ]\n",
    "non_lg0_DPSH = non_lg0[ non_lg0.loss == \"DHN\" ].copy()\n",
    "non_lg0_DPSH[\"loss\"] = \"DPSH\"\n",
    "\n",
    "results = pd.concat([lg0, non_lg0_DPSH, non_lg0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare strategies\n",
    "def stack_strategies(df, sts):\n",
    "    dfs = []\n",
    "    for st in sts:\n",
    "        df_st = df[ df.strategy == st ].copy()\n",
    "        df_st[f\"{st}_mAP\"] = df_st[\"query_mAP\"]\n",
    "        df_st[f\"{st}_l2_qe\"] = df_st[\"query_l2_qe\"]\n",
    "        del df_st[\"query_mAP\"]\n",
    "        del df_st[\"query_mAP_std\"] # need to fix\n",
    "        del df_st[\"query_l2_qe\"]\n",
    "        del df_st[\"query_l2_qe_std\"]\n",
    "        del df_st[\"strategy\"]\n",
    "        dfs.append(df_st)\n",
    "    df_final = dfs[0]\n",
    "    for df_st in dfs[1:]:\n",
    "        df_final = pd.merge(df_final, df_st, on=[\"db\", \"nbits\", \"loss\", \"arch\"])\n",
    "\n",
    "    for st in sts:\n",
    "        if st != \"l0\":\n",
    "            df_final[f\"delta_{st}\"] = df_final[f\"{st}_mAP\"] - df_final[\"l0_mAP\"]\n",
    "\n",
    "    df_final[\"winner\"] = df_final.apply(lambda row: sts[np.argmax([row[f\"{st}_mAP\"] for st in sts])], axis = 1)\n",
    "    return df_final\n",
    "\n",
    "\n",
    "strategies_to_compare = [\"l0\", \n",
    "                        \"HSWD\", \n",
    "                        \"l0+H2Q+L2\", \n",
    "                        \"l0+H2Q+L1\", \n",
    "                        \"l0+H2Q+min_entry\", \n",
    "                        \"l0+H2Q+bit_var_loss\", \n",
    "                        \"l0+ITQ\",\n",
    "                        \"l>0\"\n",
    "                        ]\n",
    "\n",
    "strategy_comparisons = stack_strategies(results, strategies_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"CNNF_alexnet\"\n",
    "\n",
    "filtered_df = strategy_comparisons[(strategy_comparisons.arch == arch)]\n",
    "\n",
    "dbs = [\"CIFAR_10\", \"NUS_WIDE\", \"MS_COCO\", \"ImageNet\"]\n",
    "\n",
    "dbs_s = [\"CIFAR 10\", \"NUS WIDE\", \"MS COCO\", \"ImageNet\"]\n",
    "\n",
    "losses_pallette = {\"DPSH\" : \"blue\", \"CEL\": \"orange\", \"DCH\": \"black\", \"WGLHH\": \"green\", \"HyP2\": \"brown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strat in [\n",
    "\"l>0\", \n",
    "\"l0+H2Q+L2\", \n",
    "\"l0+ITQ\", \n",
    "\"l0+H2Q+L1\", \n",
    "\"l0+H2Q+min_entry\", \n",
    "\"l0+H2Q+bit_var_loss\", \n",
    "\"HSWD\"\n",
    "]:\n",
    "    avg_delta_pos = (filtered_df[f\"delta_{strat}\"]>0).mean()\n",
    "    avg_delta = filtered_df[f\"delta_{strat}\"].mean()\n",
    "    avg_winner = (filtered_df[\"winner\"]==f\"{strat}\").mean()\n",
    "    max_delta = filtered_df[f\"delta_{strat}\"].max()\n",
    "    print(f\"avg_(delta_{strat})>0={avg_delta_pos}\")\n",
    "    print(f\"avg_delta_{strat}={avg_delta}\")\n",
    "    print(f\"avg_win={avg_winner}\")\n",
    "    print(f\"max_delta={max_delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [\"CEL\",\n",
    "          \"DCH\",\n",
    "          \"WGLHH\",\n",
    "          \"DPSH\",\n",
    "          \"HyP2\"\n",
    "          ]\n",
    "\n",
    "opts = [\"H2Q+L2\",\"ITQ\"]\n",
    "ms = {\"H2Q+L2\":'s', \"ITQ\":'o', \"H2Q+min_entry\":'v'}\n",
    "ls = {\"H2Q+L2\":'--', \"ITQ\":'dotted', \"H2Q+min_entry\":'dashdot'}\n",
    "\n",
    "data = strategy_comparisons[(strategy_comparisons.arch == arch) & (strategy_comparisons.loss.isin(losses))]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "\n",
    "for i, db in enumerate(dbs):\n",
    "    \n",
    "    db_data = data[data[\"db\"]==db]\n",
    "\n",
    "    plt.subplot(1,4,i+1)\n",
    "\n",
    "    for opt in opts:\n",
    "        sns.lineplot(\n",
    "            db_data,\n",
    "            x=\"nbits\", y=f\"delta_l0+{opt}\", hue=\"loss\", legend=False,\n",
    "            palette=losses_pallette,\n",
    "            linestyle=ls[opt],\n",
    "            marker=ms[opt],\n",
    "            lw=1\n",
    "        )\n",
    "\n",
    "    plt.xlabel(r\"number of bits\")\n",
    "    plt.ylabel(r\"$\\Delta$mAP\")\n",
    "    plt.title(dbs_s[i])\n",
    "    plt.xticks([16,32,48,64])\n",
    "\n",
    "handles = [\n",
    "    mlines.Line2D([], [], color='black', marker='s', linestyle='--', markersize=5),\n",
    "    mlines.Line2D([], [], color='black', marker='o', linestyle='dotted', markersize=5),\n",
    "    #mlines.Line2D([], [], color='black', marker='v', linestyle='dashdot', markersize=5),\n",
    "] + [mlines.Line2D([], [], color=losses_pallette[loss], marker='o', linestyle='None', markersize=5)\n",
    "     for loss in losses]\n",
    "\n",
    "plt.figlegend(handles, [r\"$H^2Q$\", \"ITQ\"] + losses, loc = 'upper center', ncol=9, frameon=False, bbox_to_anchor=(0.5, 1.10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"notebooks/figures/itq_h2q_{arch}_all_dbs_map_l2.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "\n",
    "for i, db in enumerate(dbs):\n",
    "    \n",
    "    db_data = data[data[\"db\"]==db]\n",
    "\n",
    "    plt.subplot(1,4,i+1)\n",
    "\n",
    "    opts = [\"H2Q+L2\", \"ITQ\"]\n",
    "\n",
    "    for opt in opts:\n",
    "        sns.lineplot(\n",
    "            db_data,\n",
    "            x=\"nbits\", y=f\"l0+{opt}_l2_qe\", hue=\"loss\", legend=False,\n",
    "            palette=losses_pallette,\n",
    "            linestyle=ls[opt],\n",
    "            marker=ms[opt],\n",
    "            lw=1\n",
    "        )\n",
    "\n",
    "    plt.xlabel(r\"number of bits\")\n",
    "    plt.ylabel(r\"$L_2$ quantization error\")\n",
    "    #plt.ylim(0.06,0.3)\n",
    "    plt.title(dbs_s[i])\n",
    "    plt.xticks([16,32,48,64])\n",
    "\n",
    "handles = [\n",
    "    mlines.Line2D([], [], color='black', marker='s', linestyle='--', markersize=5),\n",
    "    mlines.Line2D([], [], color='black', marker='o', linestyle='dotted', markersize=5),\n",
    "    #mlines.Line2D([], [], color='black', marker='v', linestyle='dashdot', markersize=5)\n",
    "] + [mlines.Line2D([], [], color=losses_pallette[loss], marker='o', linestyle='None', markersize=5)\n",
    "     for loss in losses if loss in losses]\n",
    "\n",
    "\n",
    "plt.figlegend(handles, [r\"$H^2Q$\", \"ITQ\"] + losses, loc = 'upper center', ncol=9, frameon=False, bbox_to_anchor=(0.5, 1.10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"notebooks/figures/itq_h2q_{arch}_all_dbs_l2_qe.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = [\"H2Q+L2\",\"H2Q+min_entry\",\"H2Q+L1\",\"H2Q+bit_var_loss\"]\n",
    "ms = {\"H2Q+L2\":'s', \"H2Q+min_entry\":'o', \"H2Q+L1\":'v', \"H2Q+bit_var_loss\":\"^\"}\n",
    "ls = {\"H2Q+L2\":'--', \"H2Q+min_entry\":'dotted', \"H2Q+L1\":'dashdot', \"H2Q+bit_var_loss\":\"solid\"}\n",
    "\n",
    "data = strategy_comparisons[(strategy_comparisons.arch == arch) & (strategy_comparisons.loss.isin(losses))]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "\n",
    "for i, db in enumerate(dbs):\n",
    "    \n",
    "    db_data = data[data[\"db\"]==db]\n",
    "\n",
    "    plt.subplot(1,4,i+1)\n",
    "\n",
    "    for opt in opts:\n",
    "        sns.lineplot(\n",
    "            db_data,\n",
    "            x=\"nbits\", y=f\"delta_l0+{opt}\", hue=\"loss\", legend=False,\n",
    "            palette=losses_pallette,\n",
    "            linestyle=ls[opt],\n",
    "            marker=ms[opt],\n",
    "            lw=1\n",
    "        )\n",
    "\n",
    "    plt.xlabel(r\"number of bits\")\n",
    "    plt.ylabel(r\"$\\Delta$mAP\")\n",
    "    plt.title(dbs_s[i])\n",
    "    plt.xticks([16,32,48,64])\n",
    "\n",
    "handles = [\n",
    "    mlines.Line2D([], [], color='black', marker='s', linestyle='--', markersize=5),\n",
    "    mlines.Line2D([], [], color='black', marker='o', linestyle='dotted', markersize=5),\n",
    "    mlines.Line2D([], [], color='black', marker='v', linestyle='dashdot', markersize=5),\n",
    "    mlines.Line2D([], [], color='black', marker='^', linestyle='solid', markersize=5),\n",
    "] + [mlines.Line2D([], [], color=losses_pallette[loss], marker='o', linestyle='None', markersize=5)\n",
    "     for loss in losses]\n",
    "\n",
    "plt.figlegend(handles, [r\"$H^2Q+L_2$\", r\"$H^2Q$+min_entry\", r\"$H^2Q+L_1$\", r\"$H^2Q$+bit_var_loss\"] + losses, loc = 'upper center', ncol=9, frameon=False, bbox_to_anchor=(0.5, 1.10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"notebooks/comparisons/h2q_losses_{arch}_all_dbs_map_l2.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table utils\n",
    "def get_lines(\n",
    "        df,\n",
    "        loss,\n",
    "        arch,\n",
    "        strategies,\n",
    "        nbs=[16, 32, 48, 64],\n",
    "        dbs=[\"CIFAR_10\", \"NUS_WIDE\", \"MS_COCO\", \"ImageNet\"],\n",
    "        with_std = False\n",
    "):\n",
    "    df_filtered = df[(df.loss == loss) & (df.strategy.isin(strategies)) & (df.arch == arch) & (df.nbits.isin(nbs)) & (df.db.isin(dbs))]\n",
    "    lines = []\n",
    "    for strategy in strategies:\n",
    "        line = []\n",
    "        for db in dbs:\n",
    "            for nb in nbs:\n",
    "                v = df_filtered.query_mAP[(df_filtered.db == db)&(df_filtered.strategy == strategy)&(df_filtered.nbits == nb)].values[0]\n",
    "                if with_std:\n",
    "                    s = df_filtered.query_mAP_std[(df_filtered.db == db)&(df_filtered.strategy == strategy)&(df_filtered.nbits == nb)].values[0]\n",
    "                    line.append((v,s))\n",
    "                else:\n",
    "                    line.append(v)\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines\n",
    "\n",
    "def print_table_head(no_skip=False):\n",
    "    print(\"\\\\begin{table*}[]\\\\centering\")\n",
    "    if no_skip:\n",
    "        print(\"\\\\begin{tabular}{l@{\\\\hskip .01in}|c@{\\\\hskip .01in}c@{\\\\hskip .01in}c@{\\\\hskip .01in}c|c@{\\\\hskip .01in}c@{\\\\hskip .01in}c@{\\\\hskip .01in}c|c@{\\\\hskip .01in}c@{\\\\hskip .01in}c@{\\\\hskip .01in}c|c@{\\\\hskip .01in}c@{\\\\hskip .01in}c@{\\\\hskip .01in}c}\")\n",
    "    else:\n",
    "        print(\"\\\\begin{tabular}{l|c@{\\\\hskip .08in}c@{\\\\hskip .08in}c@{\\\\hskip .08in}c|c@{\\\\hskip .08in}c@{\\\\hskip .08in}c@{\\\\hskip .08in}c|c@{\\\\hskip .08in}c@{\\\\hskip .08in}c@{\\\\hskip .08in}c|c@{\\\\hskip .08in}c@{\\\\hskip .08in}c@{\\\\hskip .08in}c}\")\n",
    "    print(\"& \\\\multicolumn{4}{c|}{CIFAR 10} & \\\\multicolumn{4}{c|}{NUS WIDE} & \\\\multicolumn{4}{c|}{MS COCO} & \\\\multicolumn{4}{c}{ImageNet} \\\\\\\\ \\\\hline\")\n",
    "    print(\"n bits & 16 & 32 & 48 & 64 & 16 & 32 & 48 & 64 & 16 & 32 & 48 & 64 & 16 & 32 & 48 & 64\\\\\\\\ \\\\hline\")\n",
    "\n",
    "def print_table_footer(caption, label):\n",
    "    print(\"\\\\end{tabular}\")\n",
    "    print(\"\\\\caption{\"+caption+\".}\")\n",
    "    print(\"\\\\label{tab:\"+label+\"}\")\n",
    "    print(\"\\\\end{table*}\")\n",
    "\n",
    "def format_lines(lines, loss_label, strategy_labels, underline=False, color_bad=False, put_separation=True):\n",
    "    has_std = False\n",
    "    if isinstance(lines[0][0], tuple):\n",
    "        has_std = True\n",
    "        lines_only_avg = [ [ v for (v,_) in line ] for line in lines]\n",
    "    else:\n",
    "        lines_only_avg = lines\n",
    "\n",
    "    best_lines = np.argmax(lines_only_avg, axis=0)\n",
    "    non_improv_lines = np.array(lines_only_avg) - np.array(lines_only_avg[0])[None, :] < 0\n",
    "\n",
    "    for i, (line, strategy_label) in enumerate(zip(lines, strategy_labels)):\n",
    "        if has_std:\n",
    "            str_line = \"{\" + f\"\\\\footnotesize {loss_label}{strategy_label}\" + \"}\"\n",
    "        else:\n",
    "            str_line = f\"{loss_label}{strategy_label}\"\n",
    "        for j, v in enumerate(line):\n",
    "            if has_std:\n",
    "                str_value = \"{\\\\footnotesize\" + f\"{v[0]:.1f}$^\" + \"{\" + f\"{v[1]:.1f}\" + \"}$}\"\n",
    "            else:\n",
    "                str_value = f\"{v:.1f}\" \n",
    "            if underline and i == best_lines[j]:\n",
    "                str_value = \"\\\\textbf{\" + str_value + \"}\"\n",
    "            if color_bad and non_improv_lines[i][j]:\n",
    "                str_value = \"{\\\\color{red}\" + str_value + \"}\"\n",
    "            str_line += \" & \"+str_value\n",
    "        if i == len(strategy_labels) - 1 and put_separation:\n",
    "            print(str_line + \"\\\\\\\\[.5em]\")\n",
    "        else:\n",
    "            print(str_line + \"\\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make single table that compares our method with the sota and no quantization\n",
    "for arch in [\"CNNF_alexnet\", \"CNNF_vgg16\"]:\n",
    "    print_table_head()\n",
    "    format_lines(get_lines(results, \"ADSH\", arch=arch, strategies=[\"ADSH\"]), \"ADSH\", strategy_labels=[\"\"], put_separation=True)\n",
    "    format_lines(get_lines(results, \"HashNet\", arch=arch, strategies=[\"continuation\"]), \"HashNet\", strategy_labels=[\"\"], put_separation=True)\n",
    "    format_lines(get_lines(results, \"CEL\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"CEL\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\", \" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DCH\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"DCH\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\",\" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DHN\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"DHN\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\",\" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DPSH\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"DPSH\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\",\" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"WGLHH\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"WGLHH\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\",\" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"HyP2\", arch=arch, strategies=[\"l0\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\"]), \"HyP²\", strategy_labels=[\" ($\\\\lambda=0$)\", \" + $\\\\lambda$\",\" + HSWD\", \" + H²Q\"], put_separation=True, underline=True, color_bad=True)\n",
    "  \n",
    "    print_table_footer(\"\\\\texttt{mAP@k} with \"+arch[5:], f\"sota_{arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make big table for the SM\n",
    "sts = [\"l0\", \"l0+ITQ\", \"l>0\", \"HSWD\", \"l0+H2Q+L2\", \"l0+H2Q+L1\", \"l0+H2Q+min_entry\", \"l0+H2Q+bit_var_loss\"]\n",
    "st_labels = [\"($\\\\lambda=0$)\", \"+ITQ\", \"+$\\\\lambda$\", \"+HSWD\", \"+H²Q($L_2$)\",  \"+H²Q($L_1$)\", \"+H²Q(min)\", \"+H²Q(bit)\" ]\n",
    "for arch in [\"CNNF_alexnet\", \"CNNF_vgg16\"]:\n",
    "    print_table_head(no_skip=True)\n",
    "    format_lines(get_lines(results, \"ADSH\", arch=arch, strategies=[\"ADSH\"], with_std=True), \"ADSH\", strategy_labels=[\"\"])\n",
    "    format_lines(get_lines(results, \"HashNet\", arch=arch, strategies=[\"continuation\"], with_std=True), \"HashNet\", strategy_labels=[\"\"])\n",
    "    format_lines(get_lines(results, \"CEL\", arch=arch, strategies=sts, with_std=True), \"CEL\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DCH\", arch=arch, strategies=sts, with_std=True), \"DCH\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DHN\", arch=arch, strategies=sts, with_std=True), \"DHN\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"DPSH\", arch=arch, strategies=sts, with_std=True), \"DPSH\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"WGLHH\", arch=arch, strategies=sts, with_std=True), \"WGL.\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    format_lines(get_lines(results, \"HyP2\", arch=arch, strategies=sts, with_std=True), \"HyP²\", strategy_labels=st_labels, underline=True, color_bad=True)\n",
    "    print_table_footer(\"\\\\texttt{mAP@k} with \"+arch[5:], f\"improve_{arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = []\n",
    "    group = 0\n",
    "    i = 0\n",
    "    while i < len(lines)-1:\n",
    "        if group % 4 == 0:\n",
    "            # train + penalty\n",
    "            name = lines[i].split('\\n')[0]\n",
    "            seed = int(lines[i + 1].split(': ')[1])\n",
    "            nbits = int(lines[i + 2].split(': ')[1])\n",
    "            start = int(lines[i + 3].split(': ')[1])\n",
    "            for j in range(4):\n",
    "                finish = int(lines[i + 4 + j].split(': ')[1])\n",
    "                data.append([f\"training {j+1} lambdas\", seed, nbits, start, finish])\n",
    "            i += 9\n",
    "        else:\n",
    "            name = lines[i].split('\\n')[0]\n",
    "            seed = int(lines[i + 1].split(': ')[1])\n",
    "            nbits = int(lines[i + 2].split(': ')[1])\n",
    "            start = int(lines[i + 3].split(': ')[1])\n",
    "            finish = int(lines[i + 4].split(': ')[1])\n",
    "            data.append([name, seed, nbits, start, finish])\n",
    "            i += 5\n",
    "        group += 1\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['strategy', 'seed', 'nbits', 'start', 'finish'])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = process_file('time_experiment.txt')\n",
    "df[\"delta\"] = df[\"finish\"] - df[\"start\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge strategies\n",
    "def merge_strategies(df, st1, st2, new_label):\n",
    "    df1 = df[df[\"strategy\"] == st1]\n",
    "    df2 = df[df[\"strategy\"] == st2]\n",
    "    joined = df1.join(df2.set_index([\"seed\", \"nbits\"]), on=[\"seed\", \"nbits\"], lsuffix=\"_\")\n",
    "    joined[\"delta\"] += joined[\"delta_\"]\n",
    "    joined = joined.drop(columns=[\"strategy_\", \"delta_\"])\n",
    "    joined[\"strategy\"] = new_label\n",
    "    return joined\n",
    "\n",
    "df_organized = pd.concat([\n",
    "    merge_strategies(df, \"training 1 lambdas\", \"predicting + penalty\", \"One penalization\"),\n",
    "    merge_strategies(df, \"training 2 lambdas\", \"predicting + penalty\", \"Two penalizations\"),\n",
    "    merge_strategies(df, \"training 3 lambdas\", \"predicting + penalty\", \"Three penalizations\"),\n",
    "    merge_strategies(df, \"training 4 lambdas\", \"predicting + penalty\", \"Four penalizations\"),\n",
    "    merge_strategies(df, \"training + H2Q\", \"prediction + H2Q\", \"H2Q\"),\n",
    "])\n",
    "df_organized.delta /= 60\n",
    "\n",
    "c_palette = {\n",
    "    \"One penalization\": \"#ff9999\",  # Light red\n",
    "    \"Two penalizations\": \"#ff6666\",  # Medium red\n",
    "    \"Three penalizations\": \"#ff3333\",  # Darker red\n",
    "    \"Four penalizations\": \"#cc0000\",  # Deep red\n",
    "    \"H2Q\": \"C0\"   # Pure red\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3.5))\n",
    "sns.boxplot(df_organized, ax=ax, x = \"nbits\", y=\"delta\", hue=\"strategy\", palette=c_palette)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Number of bits\")\n",
    "plt.ylabel(\"Time (min)\")\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "labels = [r\"$1\\lambda$\", r\"$2\\lambda s$\", r\"$3\\lambda s$\", r\"$4\\lambda s$\", \"H2Q\"]\n",
    "plt.legend(handles, labels, loc='upper center', ncol=5, bbox_to_anchor = (0, .15, 1, 1), frameon=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"time_experiment.pdf\", bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
